{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to predict active vs inactive customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "We start with our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll read our dataset with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Subscription</th>\n",
       "      <th>Refill</th>\n",
       "      <th>Interval</th>\n",
       "      <th>Price per interval</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>Products</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>DaysSinceLastOrder</th>\n",
       "      <th>SubscriptionLifetime</th>\n",
       "      <th>Active</th>\n",
       "      <th>SubscriptionLifetimeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2092329948149575290</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ideal</td>\n",
       "      <td>Brush</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12849545117712085541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ideal</td>\n",
       "      <td>Brush</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8144808881881603173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ideal</td>\n",
       "      <td>Brush</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14457143150027122736</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ideal</td>\n",
       "      <td>Brush</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9143720643862541019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ideal</td>\n",
       "      <td>Brush</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  Subscription  Refill  Interval  Price per interval  \\\n",
       "0   2092329948149575290             1       0         3                 5.0   \n",
       "1  12849545117712085541             1       0         2                10.0   \n",
       "2   8144808881881603173             1       0         2                 5.0   \n",
       "3  14457143150027122736             1       0         3                10.0   \n",
       "4   9143720643862541019             1       0         3                10.0   \n",
       "\n",
       "  PaymentMethod Products  Transactions  Revenue  DaysSinceLastOrder  \\\n",
       "0         ideal    Brush             1     54.0                 217   \n",
       "1         ideal    Brush             1     98.0                  66   \n",
       "2         ideal    Brush             1     69.0                  66   \n",
       "3         ideal    Brush             1     98.0                  66   \n",
       "4         ideal    Brush             1     98.0                  66   \n",
       "\n",
       "   SubscriptionLifetime  Active SubscriptionLifetimeBin  \n",
       "0                   217       0                    High  \n",
       "1                    66       0                  Medium  \n",
       "2                    66       0                  Medium  \n",
       "3                    66       0                  Medium  \n",
       "4                    66       0                  Medium  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"../data/data_prediction.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns - Data\n",
    "drop_cols = [\"ID\"]\n",
    "data.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at the shape of our data and the column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(945, 12)\n"
     ]
    }
   ],
   "source": [
    "# Print shape of data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummies\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imbalanced data\n",
    "The outcome classes are not equally represented and because future algorithms will assume balanced data, we need to use some techniques to handle imbalanced data.\n",
    "\n",
    "* **Up-sample Minority Class** - Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal.\n",
    "* **Down-sample Majority Class** - Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorith. We will choose not to down-sample the majority class because the data set is already relatively small.\n",
    "\n",
    "[How to handle imbalanced data](https://elitedatascience.com/imbalanced-classes)\n",
    "\n",
    "![Resampling](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    894\n",
       "1     51\n",
       "Name: Active, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check active vs inactive customers\n",
    "data[\"Active\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    894\n",
       "1    500\n",
       "Name: Active, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Up-sample Minority Class\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "data_majority = data[data[\"Active\"]==0]\n",
    "data_minority = data[data[\"Active\"]==1]\n",
    " \n",
    "# Upsample minority class\n",
    "data_minority_upsampled = resample(data_minority, \n",
    "                                   replace=True,     # sample with replacement\n",
    "                                   n_samples=500,    # to match majority class (894)\n",
    "                                   random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "data_upsampled[\"Active\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the new DataFrame has more observations than the original, and the ratio of the two classes is more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "The final step in the processing phase is to separate the data into test and train datasets. We do this to ensure that our model performs well even on the data that was not used for training. This is how we reduce overfitting. We randomly select 80% of the data for the training dataset and the remaining 20% is used for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe\n",
    "data_x = data_upsampled[data_upsampled.columns.difference([\"Active\"])]\n",
    "data_y = data_upsampled[\"Active\"]\n",
    "\n",
    "# Standardizing/scaling the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data_x = StandardScaler().fit_transform(data_x)\n",
    "\n",
    "# Create Train & Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2,random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of X_train: 1115\n",
      "Lenght of X_test: 279\n",
      "Lenght of y_train: 1115\n",
      "Lenght of y_test: 279\n"
     ]
    }
   ],
   "source": [
    "print(\"Lenght of X_train:\",len(X_train))\n",
    "print(\"Lenght of X_test:\",len(X_test))\n",
    "print(\"Lenght of y_train:\",len(y_train))\n",
    "print(\"Lenght of y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification algorithms attempt to learn patterns in the data to be able to predict the membership of new data to one or more classes/groups. Since we are trying to predict active vs inactive customers (binary problem), there are a number of algorithms at our disposal. \n",
    "\n",
    "* 1. **Logistic regression** is a good choice for our problem. \n",
    "* 2. Another good choice is **random forest**. \n",
    "* 3. **Support Vector Machine (SVM)** is also a suitable option for this type of problem. \n",
    "* 4. Last, **K-Nearest Neighbors** will be used to predict active vs inactive customers.\n",
    "\n",
    "We will create all of the above mentioned models and evaluate their accuracy afterwards as follows: \n",
    "\n",
    "* One way to evaluate the model is using a **confusion matrix**. The confusion matrix specifies how many observations were correctly classified and how many were incorrectly classified. For this project, we will select the model that minimizes False Positives (falsely '\n",
    "* Another widely used way to evalaute models is the **accuracy score**.\n",
    "* Last, we will use the classification report to check precision, recall and the F1-score\n",
    "    * **Precision** is the number of correctly classified among that class.\n",
    "    * **Recall** (Sensitivity) is the ability of a classifier to find all positive instances.\n",
    "    * **F1-score** is the harmonic mean of precision and recall.\n",
    "\n",
    "Below we will evaluate the models on the aforementioned evaluation methods for `lr_y_pred`, `rf_y_pred`, `svm_y_pred` and `knn_y_pred`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Confusion Matrix](../confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix # Confusion matrix\n",
    "from sklearn.metrics import accuracy_score # Accuracy score\n",
    "from sklearn.metrics import classification_report # Check precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "A logistic regression returns the likelihood of a binary problem based on a cutoff (default=0.5) that splits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_matrix:\n",
      " [[169   6]\n",
      " [ 46  58]]\n",
      "\n",
      "lr_score:\n",
      " 0.8136200716845878\n",
      "\n",
      "lr_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87       175\n",
      "           1       0.91      0.56      0.69       104\n",
      "\n",
      "    accuracy                           0.81       279\n",
      "   macro avg       0.85      0.76      0.78       279\n",
      "weighted avg       0.83      0.81      0.80       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Initiate model\n",
    "lr = LogisticRegression()\n",
    "lr_result = lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict response\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate prediction\n",
    "lr_matrix = confusion_matrix(y_test, lr_y_pred)\n",
    "print(\"lr_matrix:\\n\",lr_matrix)\n",
    "\n",
    "lr_score = accuracy_score(y_test, lr_y_pred)\n",
    "print(\"\\nlr_score:\\n\",lr_score)\n",
    "\n",
    "lr_report = classification_report(y_test, lr_y_pred)\n",
    "print(\"\\nlr_report:\\n\",lr_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual:\n",
      " 0    894\n",
      "1     51\n",
      "Name: Active, dtype: int64\n",
      "\n",
      "Predicted:\n",
      " 1    918\n",
      "0     27\n",
      "Name: Predicted, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## Lets manually check if active vs inactive customers are predicted correctly\n",
    "# First split the original dataframe\n",
    "data_x = data[data.columns.difference([\"Active\"])]\n",
    "data_y = data[\"Active\"]\n",
    "\n",
    "# Generate result\n",
    "result = data[[\"Active\"]]\n",
    "result[\"Predicted\"] = lr.predict(data_x)\n",
    "result.sort_values(by=\"Active\",ascending=False).head(10)\n",
    "print(\"\\nActual:\\n\",result[\"Active\"].value_counts())\n",
    "print(\"\\nPredicted:\\n\",result[\"Predicted\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "Random forest is an ensemble algorithm. This means that it resamples the data multiple times and generates a decision tree from each sample. We then think of the trees as a group of algorithms. We base our decision on the outcome of the majority of algorithms in the ensemble.\n",
    "\n",
    "Decision trees often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_matrix:\n",
      " [[158  17]\n",
      " [  6  98]]\n",
      "\n",
      "rf_score:\n",
      " 0.9175627240143369\n",
      "\n",
      "rf_score_train:\n",
      " 0.9542600896860987\n",
      "\n",
      "rf_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       175\n",
      "           1       0.85      0.94      0.89       104\n",
      "\n",
      "    accuracy                           0.92       279\n",
      "   macro avg       0.91      0.92      0.91       279\n",
      "weighted avg       0.92      0.92      0.92       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initiate model\n",
    "rf = RandomForestClassifier()\n",
    "rf_result = rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict response\n",
    "rf_y_pred = rf_result.predict(X_test)\n",
    "rf_y_pred_train = rf_result.predict(X_train)\n",
    "\n",
    "# Evaluate prediction\n",
    "rf_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "print(\"rf_matrix:\\n\",rf_matrix)\n",
    "\n",
    "rf_score = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"\\nrf_score:\\n\",rf_score)\n",
    "\n",
    "rf_score_train = accuracy_score(y_train, rf_y_pred_train)\n",
    "print(\"\\nrf_score_train:\\n\",rf_score_train)\n",
    "\n",
    "rf_report = classification_report(y_test, rf_y_pred)\n",
    "print(\"\\nrf_report:\\n\",rf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)\n",
    "SVM looks at the datapoints that are closest to the line that divide the two classes. We will used the Penalized-SVM to increase the cost of classification mistakes on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_matrix:\n",
      " [[159  16]\n",
      " [ 46  58]]\n",
      "\n",
      "svm_score:\n",
      " 0.7777777777777778\n",
      "\n",
      "svm_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       175\n",
      "           1       0.78      0.56      0.65       104\n",
      "\n",
      "    accuracy                           0.78       279\n",
      "   macro avg       0.78      0.73      0.74       279\n",
      "weighted avg       0.78      0.78      0.77       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initiate model\n",
    "svm = SVC(kernel='linear',\n",
    "          class_weight='balanced', # penalize\n",
    "          probability=True)\n",
    "svm_result = svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict response\n",
    "svm_y_pred = svm_result.predict(X_test)\n",
    "\n",
    "# Evaluate prediction\n",
    "svm_matrix = confusion_matrix(y_test, svm_y_pred)\n",
    "print(\"svm_matrix:\\n\",svm_matrix)\n",
    "\n",
    "svm_score = accuracy_score(y_test, svm_y_pred)\n",
    "print(\"\\nsvm_score:\\n\",svm_score)\n",
    "\n",
    "svm_report = classification_report(y_test, svm_y_pred)\n",
    "print(\"\\nsvm_report:\\n\",svm_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual:\n",
      " 0    894\n",
      "1     51\n",
      "Name: Active, dtype: int64\n",
      "\n",
      "Predicted:\n",
      " 0    925\n",
      "1     20\n",
      "Name: Predicted, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## Lets manually check if active vs inactive customers are predicted correctly\n",
    "# First split the original dataframe\n",
    "data_x = data[data.columns.difference([\"Active\"])]\n",
    "data_y = data[\"Active\"]\n",
    "\n",
    "# Generate result\n",
    "result = data[[\"Active\"]]\n",
    "result[\"Predicted\"] = svm.predict(data_x)\n",
    "result.sort_values(by=\"Active\",ascending=False).head(10)\n",
    "print(\"\\nActual:\\n\",result[\"Active\"].value_counts())\n",
    "print(\"\\nPredicted:\\n\",result[\"Predicted\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors (KNN)\n",
    "KNN uses the nearest datapoints to determine classes where k = the number of datapoints closest to the testpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_matrix:\n",
      " [[151  24]\n",
      " [ 14  90]]\n",
      "\n",
      "knn_score:\n",
      " 0.8637992831541219\n",
      "\n",
      "knn_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       175\n",
      "           1       0.79      0.87      0.83       104\n",
      "\n",
      "    accuracy                           0.86       279\n",
      "   macro avg       0.85      0.86      0.86       279\n",
      "weighted avg       0.87      0.86      0.86       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initiate model\n",
    "knn = KNeighborsClassifier()\n",
    "knn_result = knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict response\n",
    "knn_y_pred = knn_result.predict(X_test)\n",
    "\n",
    "# Evaluate prediction\n",
    "knn_matrix = confusion_matrix(y_test, knn_y_pred)\n",
    "print(\"knn_matrix:\\n\",knn_matrix)\n",
    "\n",
    "knn_score = accuracy_score(y_test, knn_y_pred)\n",
    "print(\"\\nknn_score:\\n\",knn_score)\n",
    "\n",
    "knn_report = classification_report(y_test, knn_y_pred)\n",
    "print(\"\\nknn_report:\\n\",knn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual:\n",
      " 0    894\n",
      "1     51\n",
      "Name: Active, dtype: int64\n",
      "\n",
      "Predicted:\n",
      " 1    945\n",
      "Name: Predicted, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## Lets manually check if active vs inactive customers are predicted correctly\n",
    "# First split the original dataframe\n",
    "data_x = data[data.columns.difference([\"Active\"])]\n",
    "data_y = data[\"Active\"]\n",
    "\n",
    "# Generate result\n",
    "result = data[[\"Active\"]]\n",
    "result[\"Predicted\"] = knn.predict(data_x)\n",
    "result.sort_values(by=\"Active\",ascending=False).head(10)\n",
    "print(\"\\nActual:\\n\",result[\"Active\"].value_counts())\n",
    "print(\"\\nPredicted:\\n\",result[\"Predicted\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that from all the models, the **RandomForest** minimizes the False Negatives the most. False Negatives are mistakes of prediciting customers that they are not going to unsubscribe (become inactive), but they actually did unsubscribe (become inactive).\n",
    "\n",
    "Based on the accuracy scores of the test and train data (0.94 vs. 0.95 respectively), it seems the data is underfitting. This is expected, because we have few rows to train the data. To start making valid predictions, it is necessary to get more training data. Ideally there would be more data and a bigger population of high-risk customers in the complete dataset.\n",
    "\n",
    "Still, let's work with what we have and calculate the class probabilities of the features for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe\n",
    "data_x = data_upsampled[data_upsampled.columns.difference([\"Active\"])]\n",
    "data_y = data_upsampled[\"Active\"]\n",
    "\n",
    "# Standardizing/scaling the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data_x = StandardScaler().fit_transform(data_x)\n",
    "\n",
    "# Create Train & Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3) # Note that here we increased the test_size with +0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual:\n",
      " 0    894\n",
      "1     51\n",
      "Name: Active, dtype: int64\n",
      "\n",
      "Predicted:\n",
      " 0    945\n",
      "Name: Predicted, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Active</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Active  Predicted\n",
       "606       1          0\n",
       "433       1          0\n",
       "338       1          0\n",
       "791       1          0\n",
       "282       1          0\n",
       "..      ...        ...\n",
       "324       0          0\n",
       "325       0          0\n",
       "327       0          0\n",
       "328       0          0\n",
       "944       0          0\n",
       "\n",
       "[945 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate model\n",
    "rf = RandomForestClassifier()\n",
    "rf_result = rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict response\n",
    "rf_y_pred = rf_result.predict(X_test)\n",
    "rf_y_pred_train = rf_result.predict(X_train)\n",
    "\n",
    "## Lets manually check if active vs inactive customers are predicted correctly\n",
    "# First split the original dataframe\n",
    "data_x = data[data.columns.difference([\"Active\"])]\n",
    "data_y = data[\"Active\"]\n",
    "\n",
    "# Generate result on original dataframe\n",
    "result = data[[\"Active\"]]\n",
    "result[\"Predicted\"] = rf.predict(data_x)\n",
    "result.sort_values(by=\"Active\",ascending=False).head(10)\n",
    "print(\"\\nActual:\\n\",result[\"Active\"].value_counts())\n",
    "print(\"\\nPredicted:\\n\",result[\"Predicted\"].value_counts())\n",
    "result.sort_values(by=\"Active\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split the original dataframe\n",
    "data_x = data[data.columns.difference([\"Active\"])]\n",
    "data_y = data[\"Active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of outcome\n",
    "pred_proba = rf.predict_proba(data_x)\n",
    "\n",
    "# Create dataframe with probability outcomes\n",
    "final_result = pd.DataFrame(pred_proba)\n",
    "final_result = final_result.rename(columns={0:\"Prob_Active\",\n",
    "                                            1:\"Prob_Inactive\"})\n",
    "final_result[\"Actual\"] = data[[\"Active\"]]\n",
    "final_result[\"Predicted\"] = rf.predict(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prob_Active', 'Prob_Inactive', 'Actual', 'Predicted'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change order of the columns\n",
    "final_result = final_result[[\"Actual\",\"Predicted\",\"Prob_Active\",\"Prob_Inactive\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though a larger dataset and more inactive customers would work better, let's divide all customers into three customer segments so that we can give practical ideas to improve the number of active customers in the long-term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Prob_Active</th>\n",
       "      <th>Prob_Inactive</th>\n",
       "      <th>ProbabilityInactive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted  Prob_Active  Prob_Inactive ProbabilityInactive\n",
       "419       1          0         0.61           0.39                 Low\n",
       "272       0          0         0.61           0.39                 Low\n",
       "273       0          0         0.61           0.39                 Low\n",
       "27        1          0         0.61           0.39                 Low\n",
       "274       0          0         0.61           0.39                 Low"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"Low\",\"Medium\",\"High\"]\n",
    "cutoff = [0,0.5,0.8,1]\n",
    "final_result[\"ProbabilityInactive\"] = pd.cut(final_result[\"Prob_Inactive\"],cutoff,labels=labels)\n",
    "final_result.sort_values(by=\"Prob_Inactive\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low       945\n",
       "High        0\n",
       "Medium      0\n",
       "Name: ProbabilityInactive, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[\"ProbabilityInactive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the result let's save it as a new csv\n",
    "final_result.to_csv(\"../data/data_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "We've modeled the risk of inactive customers and now have three customer segments:\n",
    "    1. Low - low risk of being an inactive customer (p < .3)\n",
    "    2. Medium - medium risk of being an inactive customer (p > 0.3 < .5)\n",
    "    3. High - high risk of being an inactive customer (p > 0.5)\n",
    "\n",
    "This could feed into a dashboard to give stakeholders a glimpse of \"at-risk\" customers. It also provides three different groups that we can run specific actions. Some ideas:\n",
    "\n",
    "1) Reach out to unsubscribed/inactive customers to figure out why the left. \n",
    "\n",
    "2) Send different types of targeted emails and special offers to the high risk group. If the sample size of high risk customers is large enough, you could split off a few small treatment groups and compare how their retention and CLV change with different promotional or customer relationship strategies.\n",
    "\n",
    "3) Determine the the highest value customers in the active customer group, and serve them additional benefits to ensure that they remain loyal customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
